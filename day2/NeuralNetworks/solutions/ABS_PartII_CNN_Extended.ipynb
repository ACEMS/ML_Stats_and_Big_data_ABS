{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "### Import the data for MNIST, this will be downloaded if\n",
    "### necessary or copy it over manually into the directory\n",
    "### MNIST_data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Import the tensorflow module and create a session\n",
    "import tensorflow as tf\n",
    "\n",
    "### Function to initialise the weights\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "### Function to initialise the bias variable\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Function to quickly define the 2D convolution\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "### Function to quickly define the max pooling\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### x is for the input y_ holds the output\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784]) # for the input data 28*28 image as a vector\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10]) # output layer has 10 classes\n",
    "\n",
    "### Define the input as 28x28 image with only 1 channel\n",
    "### -1 defines that there is an unspecified number of inputs\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "### Convolutional filter 1, 5x5 convolution with 32 \"filters\"\n",
    "W_conv1 = weight_variable([5, 5, 1, 64])\n",
    "b_conv1 = bias_variable([64])\n",
    "\n",
    "### Convolve the input, x_image with the filter W_conv and add the bias b_conv1\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1) # Now apply pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Define the 2nd convolutional layer\n",
    "W_conv2 = weight_variable([5, 5, 64, 128])\n",
    "b_conv2 = bias_variable([128])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "### Define the 2nd convolutional layer\n",
    "W_conv3 = weight_variable([5, 5, 128, 256])\n",
    "b_conv3 = bias_variable([256])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "h_pool3 = max_pool_2x2(h_conv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Fully connected layer\n",
    "W_fc1 = weight_variable([4 * 4 * 256, 2048])\n",
    "b_fc1 = bias_variable([2048])\n",
    "\n",
    "h_pool3_flat = tf.reshape(h_pool3, [-1, 4*4*256])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Make use of dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Define the logit/classification layer\n",
    "W_fc2 = weight_variable([2048, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Training and evaluation functions\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.14\n",
      "step 200, training accuracy 0.96\n",
      "step 400, training accuracy 1\n",
      "step 600, training accuracy 0.96\n",
      "step 800, training accuracy 1\n",
      "step 1000, training accuracy 0.94\n",
      "step 1200, training accuracy 0.98\n",
      "step 1400, training accuracy 1\n",
      "step 1600, training accuracy 0.94\n",
      "step 1800, training accuracy 0.96\n",
      "step 2000, training accuracy 0.98\n",
      "step 2200, training accuracy 0.94\n",
      "step 2400, training accuracy 0.98\n",
      "step 2600, training accuracy 0.98\n",
      "step 2800, training accuracy 1\n",
      "step 3000, training accuracy 0.98\n",
      "step 3200, training accuracy 0.96\n",
      "step 3400, training accuracy 1\n",
      "step 3600, training accuracy 0.96\n",
      "step 3800, training accuracy 0.98\n",
      "test accuracy 0.9826\n"
     ]
    }
   ],
   "source": [
    "### This is the training loop\n",
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer()) # initialise\n",
    "  for i in range(4000): # go for 20000 iterations\n",
    "    batch = mnist.train.next_batch(50) # with batches of 50\n",
    "    if i % 200 == 0:\n",
    "      train_accuracy = accuracy.eval(feed_dict={\n",
    "          x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "      print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "  print('test accuracy %g' % accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
